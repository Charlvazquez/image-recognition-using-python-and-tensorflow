{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-93d8da72a918>:2: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\anaconda\\envs\\Cuz\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\anaconda\\envs\\Cuz\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\base.py:252: _internal_retry.<locals>.wrap.<locals>.wrapped_fn (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use urllib or similar directly.\n",
      "Successfully downloaded train-images-idx3-ubyte.gz 9912422 bytes.\n",
      "WARNING:tensorflow:From C:\\anaconda\\envs\\Cuz\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Successfully downloaded train-labels-idx1-ubyte.gz 28881 bytes.\n",
      "WARNING:tensorflow:From C:\\anaconda\\envs\\Cuz\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda\\envs\\Cuz\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Successfully downloaded t10k-images-idx3-ubyte.gz 1648877 bytes.\n",
      "Extracting MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Successfully downloaded t10k-labels-idx1-ubyte.gz 4542 bytes.\n",
      "Extracting MNIST_data\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\anaconda\\envs\\Cuz\\lib\\site-packages\\tensorflow_core\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from tensorflow.examples.tutorials.mnist import input_data #mnist es para referencias el metodo que usaremos para importar nuestras imagenes de la base de datos de esta misma para nuestra practica\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True) #aqui se mandan a llamar los datos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de ejemplos de entrenamiento: 55000\n",
      "Número de ejemplos de validación: 5000\n",
      "Número de ejemplos de prueba: 10000\n",
      "Tamaño de cada dígito: 784\n",
      "Tamaño de cada etiqueta: 10\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt \n",
    "import time\n",
    "\n",
    "### Los Ejemplos de entrenamiento están en: \n",
    "# mnist.train.images\n",
    "print(\"Número de ejemplos de entrenamiento:\", mnist.train.images.shape[0])\n",
    "\n",
    "### El conjunto de validacion es: \n",
    "# mnist.validation\n",
    "print(\"Número de ejemplos de validación:\", mnist.validation.images.shape[0])\n",
    "\n",
    "\n",
    "### El conjunto de prueba es: \n",
    "# mnist.test\n",
    "print(\"Número de ejemplos de prueba:\", mnist.test.images.shape[0])\n",
    "\n",
    "\n",
    "### Cada dígito es un vector de dimensión 784 .\n",
    "print(\"Tamaño de cada dígito:\", mnist.train.images.shape[1])\n",
    "\n",
    "\n",
    "### Las etiquetas se encuentran en: \n",
    "# mnist.train.labels\n",
    "# mnist.validation.labels\n",
    "# mnist.test.labels\n",
    "\n",
    "print(\"Tamaño de cada etiqueta:\", mnist.train.labels.shape[1])\n",
    "#Cada etiqueta es un one-hot-vector,ie. un vector con un solo uno, las demás entradas son cero\n",
    "#[1,0,0,0,0,0,0,0,0,0]  representa el número 0\n",
    "#[0,1,0,0,0,0,0,0,0,0]  representa el número 1\n",
    "#   .\n",
    "#   .\n",
    "#   ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cada dígito se almacena como un vector de 784 dimensiones. Para visualizarlo, primero lo redimensionamos a una imagen de 28x28.\n",
    "def muestra_digito(x):\n",
    "    \"\"\"\n",
    "        x: vector \n",
    "            784 dimensiones\n",
    "        Muestra el vector como una imágen de 28x28\n",
    "    \"\"\"\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "def vis_imagen(i, conjunto=\"train\"):\n",
    "    \"\"\"\n",
    "        i indice del conjunto especificado\n",
    "        conjunto: cadena\n",
    "            Cualquiera: train, validation, test\n",
    "            \n",
    "        Muestra el dígito en el indice i  y su etiqueta\n",
    "    \"\"\"\n",
    "    if(conjunto==\"train\"): \n",
    "        muestra_digito(mnist.train.images[i,])\n",
    "        label = np.argwhere(mnist.train.labels[i])[0][0]\n",
    "    elif(conjunto==\"test\"): \n",
    "        muestra_digito(mnist.test.images[i,])\n",
    "        label = np.argwhere(mnist.test.labels[i])[0][0]\n",
    "    else:\n",
    "        muestra_digito(mnist.validation.images[i,])\n",
    "        label = np.argwhere(mnist.validation.labels[i])[0][0]\n",
    "    print(\"Etiqueta \" + str(label))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 7\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAFKklEQVR4nO3dMUuVbRzH8XNX2NAryEk3oYZegK1BEDU4OIWz5eQilGsgNNraWKF7pIuDQ67iKkLQ3hAhlOb9bM907v95Hj15fic/n9Ef9/GAfLvACztN27Y9IM+1Ub8BoD9xQihxQihxQihxQqgb1dg0jV/lwh/Wtm3T7+tOTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTgglTghVfgQgeRYXF8t9dXW13G/fvl3ua2trnduLFy/KZxkuJyeEEieEEieEEieEEieEEieEEieEcs85Ardu3ercqnvGXq/Xe/78ebm3bVvuJycn5X56etq53bx5s3z258+f5c7/4+SEUOKEUOKEUOKEUOKEUOKEUOKEUO45R2B6erpze/bs2R/93oPuQc/Ozjq369evD/vtUHByQihxQihxQihxQihxQihxQihXKVfMp0+fyn1vb69zOz4+HvbboeDkhFDihFDihFDihFDihFDihFDihFDuOUfgx48fndvHjx/LZx89enSh7725uVnu29vbF3p9hsfJCaHECaHECaHECaHECaHECaHECaHcc47Aly9fOrfHjx+Xz1b/dSV/FycnhBInhBInhBInhBInhBInhBInhHLPecU8efKk3D98+HBJ74RBnJwQSpwQSpwQSpwQSpwQSpwQSpwQqmnbtntsmu6RkRj095zVz7PXG/wZm/fv3+/c9vf3y2c5n7Ztm35fd3JCKHFCKHFCKHFCKHFCKHFCKFcpY+b169flvry8fKHXf/v2bee2tLRUPvvr168Lfe+rylUKjBlxQihxQihxQihxQihxQihxQij3nGPmzp075b61tVXuk5OT5/7eU1NT5f7169dzv/ZV5p4Txow4IZQ4IZQ4IZQ4IZQ4IZQ4IZR7zr/M7Oxsue/u7p77tZ8+fVru7969O/drX2XuOWHMiBNCiRNCiRNCiRNCiRNCiRNC3Rj1G+ByDfqIwMr8/Hy5u+ccLicnhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhBInhPJfY/5lXr16Neq3wJA4OSGUOCGUOCGUOCGUOCGUOCGUOCGUe84xs7KyUu47OzvlPjs7W+7fv3/v3NbX18tnGS4nJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4Rq2rbtHpume2Qkzs7Oyr36ef4Xa2trndvLly8v9Nr017Zt0+/rTk4IJU4IJU4IJU4IJU4IJU4I5U/GzuHevXvlvrCwUO4PHjzo3I6Ojspnm6bvb93/Negq5eTkpNwPDg7Kncvj5IRQ4oRQ4oRQ4oRQ4oRQ4oRQ4oRQ7jn7mJqaKve5ublyX1paKvdr17r/TZyZmSmfHXSPeXh4WO5v3rwp942NjXLn8jg5IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IdSVvOe8e/duuT98+LDcf//+Xe6np6flPjEx0bm9f/++fPbz58/lPuie8tu3b+VODicnhBInhBInhBInhBInhBInhBInhPIRgDBiPgIQxow4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IZQ4IVT5EYDA6Dg5IZQ4IZQ4IZQ4IZQ4IZQ4IdQ/ksDRtvmtfFkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 3\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAFL0lEQVR4nO3dsUvUfxzH8fuGpuESDUG2uOQqSLQ1NOQqCP0DbtLgUg0hhDhKW39AY2OBs4OLS65BOms0iCA4tPT9zcF93+KpP1/nPR7jvbjjuzz7QB/Oa9q27QF57tz0AwD9iRNCiRNCiRNCiRNCjVVj0zT+KxeuWdu2Tb/XnZwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQSpwQqvwJQLiI2dnZct/d3S33k5OTzm1ubq5879nZWbkPIycnhBInhBInhBInhBInhBInhBInhHLPyZVZWVkp9/v375f70tJS5zY+Pj7QMw0zJyeEEieEEieEEieEEieEEieEEieEatq27R6bpntk5Lx7967c19fXy/3v37/lPjU1deFnug3atm36ve7khFDihFDihFDihFDihFDihFC+MsY/Hj582Lm9evWqfO/du3fLfW1tbaBnGlVOTgglTgglTgglTgglTgglTgglTgjlnpN/vH79unObn58v33t0dFTunz9/HuSRRpaTE0KJE0KJE0KJE0KJE0KJE0KJE0K55xwxjx49Kvfl5eXO7c6d+t/yg4ODcv/161e58y8nJ4QSJ4QSJ4QSJ4QSJ4QSJ4QSJ4RyzzliqnvMXq/Xm56e7tzO+wm/b9++DfRM9OfkhFDihFDihFDihFDihFDihFDihFBN27bdY9N0j0S6d+9euR8fH5f7xMRE57a5uVm+98OHD+X+58+fch9Vbds2/V53ckIocUIocUIocUIocUIocUIoXxm7Zd6/f1/uk5OT5V5drX39+rV8r6uSq+XkhFDihFDihFDihFDihFDihFDihFDuOYfMs2fPyv3NmzeX+vyPHz92bt+/f7/UZ3MxTk4IJU4IJU4IJU4IJU4IJU4IJU4I5U9jhhkbq6+et7a2yn1hYaHcf//+Xe5Pnz7t3A4PD8v3Mhh/GhOGjDghlDghlDghlDghlDghlDghlO9zhlleXi73ly9flnt1b93rnf93bd1l5nByQihxQihxQihxQihxQihxQihxQijf57wB1W9k7u/vl+99/Phxue/s7JT7ixcvyp3/n+9zwpARJ4QSJ4QSJ4QSJ4QSJ4TylbEb8OnTp87tvKuSHz9+lPvi4uJAz0QeJyeEEieEEieEEieEEieEEieEEieEcs95DR48eFDuz58/H/izt7e3y/309HTgzyaLkxNCiRNCiRNCiRNCiRNCiRNCiRNCuee8BisrK+X+5MmTzu3nz5/le1dXVwd6JoaPkxNCiRNCiRNCiRNCiRNCiRNCiRNCuee8BhsbG+Ve/ezily9frvpxGFJOTgglTgglTgglTgglTgglTgjlKqWPmZmZct/c3LzU5+/t7XVu1c8DMlqcnBBKnBBKnBBKnBBKnBBKnBBKnBDKPWcf591zLi0tXerz375927kdHx9f6rO5PZycEEqcEEqcEEqcEEqcEEqcEEqcEMo9Zx9HR0flfnJyUu5N05T74eHhhZ+J0ePkhFDihFDihFDihFDihFDihFDihFBN9XN0TdN0j8CVaNu278W4kxNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNCiRNClT8BCNwcJyeEEieEEieEEieEEieEEieE+g+HlrKTy3n2HgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "vis_imagen(0, conjunto=\"train\")\n",
    "vis_imagen(132, conjunto=\"validation\")\n",
    "vis_imagen(32, conjunto=\"test\")\n",
    "vis_imagen(50000, conjunto=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 784]) #correspondiente a las imagenes y el tamaño de estas mismas\n",
    "y = tf.placeholder(tf.float32, shape=[None, 10]) #correspondiente a los labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Capa 1\n",
    "W_1 = tf.Variable(tf.truncated_normal(shape = [784,512], stddev=0.2)) #los 784 pertenecen al tama;o de nuestro vector de imagenes y el 512 el numero de unidades de nuestra red, nunca iniciar la de peso W con zero.\n",
    "b_1 = tf.Variable(tf.zeros([512]))\n",
    "\n",
    "### Capa 2 de salida\n",
    "W_2 = tf.Variable(tf.truncated_normal(shape = [512,10], stddev=0.2))\n",
    "b_2 = tf.Variable(tf.zeros([10]))\n",
    " ##En caso de agregar otra capa , los valores en la parte del shape tienen que coincidir principalmente el ultimo de la anterior \"512\", tiene que coincidir con el primero de la nueva capa \"512\", por otro lado en la ultima parte de la capa va nuestra ultima salida en este caso el 10, ya que tiene que coincidir con la dimensionalidad que establecio en los labels \"y\","
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NN(x):\n",
    "    \"\"\"\n",
    "        x: matriz\n",
    "            su forma  debe ser (m, 784)\n",
    "            \n",
    "        regresa la activación de la capa de salida\n",
    "        matriz de (m, 10)\n",
    "    \"\"\"\n",
    "    # Capa Escondida 1. \n",
    "    z_1 = tf.matmul(x,W_1) + b_1 ### Combinación lineal\n",
    "    a_1  = tf.nn.relu(z_1)     ### Activación (función no lineal)\n",
    "    \n",
    "    # Capa 2. Está es la capa de salida\n",
    "    z_2 = tf.matmul(a_1,W_2) + b_2 ### Combinación lineal\n",
    "    \n",
    "   \n",
    "    #igual aqui se repetiria el mismo procedimiento de agregar una nueva capa \n",
    "    return z_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-9-6f79d076bfed>:2: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See `tf.nn.softmax_cross_entropy_with_logits_v2`.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_ = NN(x)\n",
    "cross_entropy = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y_, labels = y)) #aqui en esta capa se reciben las predicciones de nuestro modelo, y esta sera nuestra funcion de costos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = tf.nn.softmax(y_) # predicciones en el conjunto de entrenamiento\n",
    "### Nota: la función softmax calcula la probabilidad de cada etiqueta del 0 al 9.\n",
    "#Para obtener la predicción necesitamos usar las función tf.argmax(y_,1) o su versión en python np.argmax(y_,1)\n",
    "#Así se elige el dígito más probable para la imágen\n",
    "#Esto lo hace la función precision\n",
    "\n",
    "y_valid = NN(mnist.validation.images)\n",
    "valid_pred = tf.nn.softmax(y_valid) # predicciones en el conjunto de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.train.GradientDescentOptimizer(0.5).minimize(cross_entropy) #esto sera nuestro optimizador que sera empleado para disminuir el numero de errores al momento del entrenamiento el conocido learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.Session() #Crea una sessión\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Precisión\n",
    "def precision(predicciones, etiquetas):\n",
    "    return (100.0 * np.sum(np.argmax(predicciones, 1) == np.argmax(etiquetas, 1))\n",
    "          / predicciones.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrenamiento:\n",
      "Costo del minibatch hasta el paso 0: 5.654846\n",
      "Precisión en el conjunto de entrenamiento: 15.0%\n",
      "Precision en el conjunto de validación: 35.2%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 500: 0.118802\n",
      "Precisión en el conjunto de entrenamiento: 99.0%\n",
      "Precision en el conjunto de validación: 95.7%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 1000: 0.037296\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 96.9%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 1500: 0.033395\n",
      "Precisión en el conjunto de entrenamiento: 99.0%\n",
      "Precision en el conjunto de validación: 97.4%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 2000: 0.118039\n",
      "Precisión en el conjunto de entrenamiento: 96.0%\n",
      "Precision en el conjunto de validación: 97.1%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 2500: 0.025312\n",
      "Precisión en el conjunto de entrenamiento: 99.0%\n",
      "Precision en el conjunto de validación: 97.8%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 3000: 0.014632\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 98.1%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 3500: 0.015928\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 98.0%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 4000: 0.011054\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 98.0%\n",
      "\n",
      "\n",
      "Costo del minibatch hasta el paso 4500: 0.009301\n",
      "Precisión en el conjunto de entrenamiento: 100.0%\n",
      "Precision en el conjunto de validación: 98.0%\n",
      "\n",
      "\n",
      "Wall time: 16.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "pasos = 5000\n",
    "\n",
    "print(\"Entrenamiento:\")\n",
    "for i in range(pasos):\n",
    "    batch = mnist.train.next_batch(100)\n",
    "    _,costo,predicciones =  sess.run([opt, cross_entropy, train_pred],  feed_dict={x: batch[0], y: batch[1]})\n",
    "    \n",
    "    if (i % 500 == 0):\n",
    "        print(\"Costo del minibatch hasta el paso %d: %f\" % (i, costo))\n",
    "        print(\"Precisión en el conjunto de entrenamiento: %.1f%%\" % precision(predicciones, batch[1]))\n",
    "        print(\"Precision en el conjunto de validación: %.1f%%\" % precision(\n",
    "        valid_pred.eval(session=sess), mnist.validation.labels))\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de PRUEBA: 97.8%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "y_test = NN(mnist.test.images)\n",
    "test_prediction = tf.nn.softmax(y_test)\n",
    "print(\"Precisión en el conjunto de PRUEBA: %.1f%%\" % precision(test_prediction.eval(session = sess), mnist.test.labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicción: 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAOcAAADnCAYAAADl9EEgAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAEyElEQVR4nO3cL2vVbQDH4Z0HX8IEwWIwyJJNhpoEg9FmEZPdYDAJvgHtKgaDRQwmYUXfgdEi+AdccQYtMpDfkx/w3DxuZzuf464r7ssZd/lww27OZtM0rQE9/yz7AMDviROixAlR4oQocULUsdE4m838KRcO2DRNs9/93M0JUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTogSJ0SJE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFKnBAlTog6tuwD8F+nT58e7k+ePBnu9+7dG+5bW1t/fCaWw80JUeKEKHFClDghSpwQJU6IEidEeeeMuXv37nC/cOHCcL9+/fpwf/PmzXDf3d0d7hweNydEiROixAlR4oQocUKUOCHKU0rM2bNnh/s0TcN9c3NzuG9sbAz3t2/fDncOj5sTosQJUeKEKHFClDghSpwQJU6I8s65Yr59+zbcnz59Otw/f/68yONwgNycECVOiBInRIkTosQJUeKEKHFClHfOFbO9vT3cv3//Ptx3dnYWeRwOkJsTosQJUeKEKHFClDghSpwQJU6I8s4Z8+jRo+F+//794X7ixIlFHoclcnNClDghSpwQJU6IEidEiROixAlR3jlj1tfX9/X5L1++LOgkLJubE6LECVHihChxQpQ4IUqcEOUpJWZ3d3dfn//58+eCTsKyuTkhSpwQJU6IEidEiROixAlR4oQo75wx+33nfPbs2YJOwrK5OSFKnBAlTogSJ0SJE6LECVHihCjvnEtw5syZudu1a9f29bvPnTs33Le2tvb1+zk8bk6IEidEiROixAlR4oQocUKUOCHKO+cSvHv3bu526dKl4We3t7eH+8bGxnD3zrk63JwQJU6IEidEiROixAlR4oQocUKUd86YnZ2d4f7q1atDOgnL5uaEKHFClDghSpwQJU6IEidEzaZpmj/OZvNHluLly5fD/fjx48N9c3NzkcdhAaZpmv3u525OiBInRIkTosQJUeKEKHFClDghylfGVsyvX7+G+8mTJ4f7+vr6cP/69esfn4mD4eaEKHFClDghSpwQJU6IEidEiROifJ9zxZw/f364v379erjfvn17uD948OBPj8Q++T4nrBhxQpQ4IUqcECVOiBInRIkTorxz/mU+ffo03D9+/DjcL168uMjj8D9454QVI06IEidEiROixAlR4oQo/xrzL/PixYvhfvPmzeF+6tSpuduHDx/2cCL2ys0JUeKEKHFClDghSpwQJU6IEidE+crYX+by5cvD/fnz58P98ePHc7dbt27t6UyM+coYrBhxQpQ4IUqcECVOiBInRIkTorxzHjF37twZ7jdu3Ji7XblyZfjZ9+/f7+VIR553Tlgx4oQocUKUOCFKnBAlTogSJ0R55zxiRv+Xdm1tbe3hw4dztx8/fgw/e/Xq1b0c6cjzzgkrRpwQJU6IEidEiROixAlR4oQo75ywZN45YcWIE6LECVHihChxQpQ4IUqcECVOiBInRIkTosQJUeKEKHFClDghSpwQJU6IEidEiROixAlR4oQocUKUOCFq+K8xgeVxc0KUOCFKnBAlTogSJ0SJE6L+BaiPswp4szCpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Etiqueta 1\n"
     ]
    }
   ],
   "source": [
    "indice = 251\n",
    "p = tf.argmax(NN(mnist.test.images[indice:indice+1]).eval(session = sess),1)\n",
    "print(\"Predicción:\", sess.run(p)[0])\n",
    "vis_imagen(indice, conjunto=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_transparency(im, bg_colour=(255, 255, 255)):\n",
    "\n",
    "    # Only process if image has transparency \n",
    "    if im.mode in ('RGBA', 'LA') or (im.mode == 'P' and 'transparency' in im.info):\n",
    "\n",
    "        # Need to convert to RGBA if LA format due to a bug in PIL \n",
    "        alpha = im.convert('RGBA').split()[-1]\n",
    "\n",
    "        # Create a new background image of our matt color.\n",
    "        # Must be RGBA because paste requires both images have the same format\n",
    "\n",
    "        bg = Image.new(\"RGBA\", im.size, bg_colour + (255,))\n",
    "        bg.paste(im, mask=alpha)\n",
    "        return bg\n",
    "\n",
    "    else:\n",
    "        return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imágen:o.png\n",
      "Predicción: 5\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "imagen = \"o.png\"\n",
    "img = Image.open('o.png')\n",
    "img = remove_transparency(img).convert('L')\n",
    "\n",
    "if  img.size != (28,28):\n",
    "    img.thumbnail((28,28), Image.ANTIALIAS)\n",
    "\n",
    "entrada = np.array(img, dtype = np.float32)\n",
    "entrada = entrada.reshape((1,784))\n",
    "entrada = entrada/255.0\n",
    "        \n",
    "p = tf.argmax(NN(entrada).eval(session = sess),1)\n",
    "print(\"Imágen:{}\".format(imagen))\n",
    "img.show()\n",
    "print(\"Predicción:\", sess.run(p)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
